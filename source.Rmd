---
title: "A Approach to Predictive Policing by Team RAAS"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Load Required packages
```{r libraries}
library(tibble)
library(dplyr)
library(magrittr)
library(readr)
library(zipcode)
library(lubridate)
library(stringr)
library(ggplot2)
library(forcats)
library(plotly)
library(scales)
library(MESS)
library(caret)
data("zipcode")
```

# 1. Data Reading
*Objective : Read CSV from data source*
- Following chunk reads the source csv and loads only required attributes into a dataframe object for the use
*Following chunk performs Data Reading*
```{r Reading, echo=TRUE}

dallas<-read_csv('https://www.dropbox.com/s/7ldxwrsyd10zx95/Police_Incidents.csv?dl=1')
dallas%<>%select(`Service Number ID`,`Type  Location`,`Division`,`Sector`,`Council District`,`Call Received Date Time`,`Victim Gender`,`Victim Age at Offense`,`Offense Status`,`NIBRS Crime Category`,`Zip Code`)
#as_tibble(dallas)
#summary(dallas)
```

# 2. Data Pre-processing
*Objective : Generate dataframes dallas_incidents,dallas_crime_type and dallas_crime_rate. Dataframe dallas_indcidents must be suitable for Exploratory data analysis.*
- Filter the required attributes and ignore the non-NA values
- Transforms the attribute 'call received date time' string to R datetime object and sort them in ascending order  
- Compute a new attribute 'week of the day'(name of the weekday, incident occured viz Mon,Tue and so on), 'rounded time'(Hours being rounded off to closest value and only hour value is extracted from the rounded date) and week number from 'call recieved date time'
- Transform values of 'rounded time' to four ordinal values and compute 'time slot of occurence' attribute.
- Clean the dataset to include data only from the city "Dallas"
- To remove short head and to keep dataset symmetric, filter rows corresponding to value from "12/31/2016 23:59:59" to "01/06/2019 00:00:00" (This date range consists of equal number of Mon,Tues,Wed etc of 105 counts)
- Unselect the attributes that are not further required.
*Following chunk performs Transformation/Cleaning*
```{r Transformation/Cleaning}
time_slot_vec=seq(0,24,6)
labels_vec=c("0-6","7-12","13-18","19-23")

dallas$`Zip Code`=clean.zipcodes(dallas$`Zip Code`)

#Dataframe dallas_incidents suitable for visualizing data
dallas_incidents<-dallas%>%
   filter(!is.na(`Offense Status`) & !is.na(`Division`) & !is.na(`Call Received Date Time`) & !is.na(`Zip Code`)  & !is.na(`Victim Age at Offense`) & !is.na(`NIBRS Crime Category`) & !is.na(`Type  Location`) & !is.na(Sector) & !is.na(`Council District`))%>%
  inner_join(zipcode, by = c("Zip Code" = "zip"))%>%
  filter(`city`=="Dallas")%>%
  mutate(`Division`=str_to_upper(str_replace(`Division`," ","")))%>%
  mutate(`Call Received Date Time`= as_datetime(mdy_hms(`Call Received Date Time`)))%>%
  filter(`Call Received Date Time`>as_datetime(mdy_hms("12/31/2016 23:59:59")) &  `Call Received Date Time`<as_datetime(mdy_hms("12/31/2018 23:59:59")))%>%
  mutate(`week of the day`=lubridate::wday(`Call Received Date Time`,label = TRUE, abbr = FALSE),`week number of the day`=lubridate::wday(`Call Received Date Time`),`rounded time`=hour(round_date(`Call Received Date Time`,"hour")))%>%
  mutate(`time slot of occurence`=cut(`rounded time`,breaks = time_slot_vec,labels = labels_vec,include.lowest = TRUE))%>%
  arrange(`Call Received Date Time`)%>%
  select(-`city`,-`state`,-`latitude`,-`longitude`)

```
# 3. Exploratory Data Analysis
*Objective : To evaluate the pattern/trend in the dataset that could 1. Answer some basic questions 2. Help in selecting attributes for predictive analysis*

3.1 What crimes are frequent?

*Following can be interpreted from the graph*
-

```{r ggplot_frq_crime, echo=FALSE}
ggplot_frq_crime<-dallas_incidents%>%
  ggplot(aes(fct_infreq(`NIBRS Crime Category`),fill=`NIBRS Crime Category`))+geom_bar(position = "stack") +  labs(title="Crime Categories Frequency", subtitle="count for every kind of crime that occured", y="Frequency", x="Crime") + coord_flip() + theme(legend.position="none")

ggplotly(ggplot_frq_crime)
```

3.2 How Gender and the time of crime are related and volume of crime for each time slot.

*Following can be interpreted from the graph*
-

```{r dallas_gender_and_timeslot, echo=FALSE}
dallas_gender_and_timeslot<-dallas_incidents%>%
filter( (`Victim Gender`=="Male" | `Victim Gender`=="Female"))%>%
  group_by(`Victim Gender`,`time slot of occurence`)%>%
  summarise (`number of crimes` = n()) %>%
  mutate(percentage = sprintf("%.1f%%",(`number of crimes` / sum(`number of crimes`))*100))

ggplot_dgt<-ggplot(dallas_gender_and_timeslot,aes(x=`Victim Gender`,y=`number of crimes`,label=percentage, fill = `time slot of occurence`))  +
  geom_bar(position = "stack",stat = "identity")+geom_text( size = 3, position = position_stack(vjust = 0.5))+labs(x = "Victim Gender",y="Number of Crimes",title="Victim Gender and corresponding Time Slot of Crime Occurence")
ggplotly(ggplot_dgt)
```

3.3 How crimes relate to the time of day

*Following can be interpreted from the graph*
-

```{r dallas_crime_and_timeslot, echo=FALSE}
dallas_crime_and_timeslot<-dallas_incidents%>%
  group_by(`NIBRS Crime Category`,`time slot of occurence`)%>%
  summarise(`number of crimes` = n())%>%
  arrange(`number of crimes`,.by_group = TRUE)

ggplot_dct=ggplot(dallas_crime_and_timeslot,aes(x=reorder(`NIBRS Crime Category`,-`number of crimes`),y=`number of crimes`, fill = `time slot of occurence`)) +geom_bar(position = "stack",stat = "identity")+coord_flip()+labs(x="NIBRS Crime Category",y="Number of Crimes",title = "NIBRS Crime category and corresponding Time Slot of Occurence")
ggplotly(ggplot_dct)
```

3.4 How crimes are related to days of the week and time slot of occurence

*Following can be interpreted from the graph*
-

```{r dallas_crime_rate_per_week_and_timeslot, echo=FALSE}
dallas_crime_rate_per_week_and_timeslot<-dallas_incidents%>%
  group_by(`time slot of occurence`,`week of the day`)%>%
  summarize(`number of crimes` = n())%>%
  mutate(percentage = sprintf("%.1f%%",(`number of crimes` / sum(`number of crimes`))*100))

ggplot_dcrwt=dallas_crime_rate_per_week_and_timeslot%>%
  ggplot(aes(x=`week of the day`,y=`number of crimes`, fill = `time slot of occurence` , label=percentage)) +geom_bar(position = "stack",stat = "identity")+geom_text( size = 3, position = position_stack(vjust = 0.5))+coord_flip()+labs(x="Day in the Week",y="Number of Crimes",title = "Days of Week and Corresponding observed Crimes per Time Slot")

ggplotly(ggplot_dcrwt)
```

 

3.5 How crime rate varies in the week

*Following can be interpreted from the graph*
-



```{r dallas_crime_rate_per_week, echo=FALSE}

dallas_crime_rate_per_week<-dallas_incidents%>%
  select(`rounded time`,`Division`,`week of the day`)%>%
  group_by(`rounded time`,`Division`,`week of the day`)%>%
  summarize(`number of crimes` = n())

ggplot_crw<-ggplot(dallas_crime_rate_per_week, aes(x=dallas_crime_rate_per_week$`week of the day`, y=dallas_crime_rate_per_week$`number of crimes`)) + geom_violin(trim=FALSE,fill='#56B4E9', color="black")
ggplotly(ggplot_crw)
```

# 4. Feature Selection for Predictive Analysis
*Two types of problems were designed for the given dataset : 1. Regression, 2. Classification*

*Objectives : 1. Evaluate attributes and their correlation, 2. Generate datasets dallas_crime_rate(regression) and dallas_crime_type(classification) suitable to solve the designed problems*

## 4.1 Feature Selection for Regression problem

### 4.1.1 Following chunk performs the generation of dataframe dallas_crime_rate

*Following steps taken to generate dallas_crime_rate dataframe*
- All steps to generate dallas_incidents dataframe
- group by 'Division', 'rounded time' and 'week number of the day' and summarize the frequency of records to new attribute 'freq'

*Following steps were completed done during preliminary features selection phase :*
- Reduction of Location Type attribute to 4 categorical values from 73
```{r dallas_crime_rate}

type_location_bins<-tribble(
  ~Sub,~LocationType,~LocNum,
  "Highway, Street, Alley ETC","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Airport - Love Field","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Medical Facility","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Financial Institution","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Bank/Savings And Loan","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Construction Site","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Religious Institution","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Government Facility","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Church/Synagogue/Temple/Mosque","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Shopping Mall","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Parking Lot (Park)","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Airport - All Others","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Jail/Prison/Penitentiary/Corrections Fac","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School - Elementary/Secondary","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "ATM Separate from Bank","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Daycare Facility","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Military Installation","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Outdoor Area Public/Private","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Amusement Park","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "PHARM","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Park","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Arena/Stadium/Fairgrounds/Coliseum","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School/Daycare","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "City Park/Rec/Tennis/Golf/Trail","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School - College/University","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Government/Public Building","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Community/ Recreation Center","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Dock/Wharf/Freight/Modal Terminal","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Shelter - Mission/Homeless","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School/College","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Camp/Campground","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Lake/Waterway/Beach","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Apartment Complex/Building","Private/Individual Locations (Residences and others)",4,
  "Convenience Store","Commercial Establishments (Restaurants/Stores)",2,
  "Gas or Service Station","Commercial Establishments (Restaurants/Stores)",2,
  "Bar/NightClub/DanceHall ETC.","Commercial Establishments (Restaurants/Stores)",2,
  "Parking Lot (Apartment)","Private/Individual Locations (Residences and others)",4,
  "Entertainment/Sports Venue","Commercial Establishments (Restaurants/Stores)",2,
  "Parking (Business)","Commercial Establishments (Restaurants/Stores)",2,
  "Storage Facility","Commercial Establishments (Restaurants/Stores)",2,
  "Single Family Residence - Vacant","Private/Individual Locations (Residences and others)",4,
  "Department/Discount Store","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Condominium/Townhome Residence","Private/Individual Locations (Residences and others)",4,
  "Shopping Mall","Commercial Establishments (Restaurants/Stores)",2,
  "Grocery/Supermarket","Commercial Establishments (Restaurants/Stores)",2,
  "Specialty Store (In a Specific Item)","Commercial Establishments (Restaurants/Stores)",2,
  "Personal Services","Private/Individual Locations (Residences and others)",4,
  "Tribal Lands","Private/Individual Locations (Residences and others)",4,
  "Restaurant/Food Service/TABC Location","Commercial Establishments (Restaurants/Stores)",2,
  "Apartment Residence","Private/Individual Locations (Residences and others)",4,
  "Single Family Residence - Occupied","Private/Individual Locations (Residences and others)",4,
  "Retail Store","Commercial Establishments (Restaurants/Stores)",2,
  "Business Office","Commercial Establishments (Restaurants/Stores)",2,
  "Motor Vehicle","Private/Individual Locations (Residences and others)",4,
  "Commercial Property Occupied/Vacant","Commercial Establishments (Restaurants/Stores)",2,
  "Industrial/Manufacturing","Commercial Establishments (Restaurants/Stores)",2,
  "Hotel/Motel/ETC","Commercial Establishments (Restaurants/Stores)",2,
  "Auto Dealership New/Used","Commercial Establishments (Restaurants/Stores)",2,
  "Liquor Store","Commercial Establishments (Restaurants/Stores)",2,
  "Rental Storage Facility","Commercial Establishments (Restaurants/Stores)",2,
  "Other","Others",3,
  "Cyberspace","Others",3
)

dallas_crime_rate<-dallas_incidents%>%
  select(`rounded time`,`week number of the day`,`Division`,`Type  Location`)%>%
  inner_join(type_location_bins, by = c("Type  Location" = "Sub"))%>%
  mutate(`rounded time`=factor(`rounded time`),`week number of the day`=factor(`week number of the day`),`Division`=factor(`Division`),LocationType = factor(LocationType))%>%
  group_by(`Division`,`rounded time`,`week number of the day`)%>%
  summarise(freq=n())

```
### 4.1.2 Following chunk performs evaluation of variable importance using boxplot/violinplot visualizations and anova method

*Following combinations of attributes were considered for the evaluation*

*Following interpretations can be drawn from the tests*
```{r feature selection (regression)}
d_mod=lm(dallas_crime_rate$`freq` ~ dallas_crime_rate$`Division`+dallas_crime_rate$`week number of the day`+dallas_crime_rate$`rounded time`, data = dallas_crime_rate) 
summary(d_mod)
anova(d_mod)
#confint(d_mod)
print(as_tibble(dallas_crime_rate))
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`rounded time`, y=dallas_crime_rate$`freq`)) + geom_boxplot()
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`Division`, y=dallas_crime_rate$`freq`)) + geom_boxplot()
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`week number of the day`, y=dallas_crime_rate$`freq`)) + geom_boxplot()


```
```{r feature selection (regression)}
d_mod=lm(dallas_crime_rate$`freq` ~ dallas_crime_rate$`Division`+dallas_crime_rate$`week number of the day`+dallas_crime_rate$`rounded time`, data = dallas_crime_rate) 
summary(d_mod)
anova(d_mod)
#confint(d_mod)
print(as_tibble(dallas_crime_rate))
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`rounded time`, y=dallas_crime_rate$`freq`)) + geom_violin(trim=FALSE,fill='#56B4E9', color="black")
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`Division`, y=dallas_crime_rate$`freq`)) + geom_violin(trim=FALSE,fill='#56B4E9', color="black")
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`week number of the day`, y=dallas_crime_rate$`freq`)) + geom_violin(trim=FALSE,fill='#56B4E9', color="black")


```
## 4.2 Feature Selection for Classification problem 
### 4.2.1 Following chunk performs the generation of dataframe dallas_crime_type

*Following steps taken to generate dallas_crime_type dataframe*
- All steps to generate dallas_incidents dataframe
- group by 'Division', 'rounded time' and 'week number of the day' and summarize the frequency of records to new attribute 'freq'

*Following steps were completed during preliminary features selection phase :*
- Reduction of Location Type attribute to 4 categorical values from 73
- Usage of 'NIBRS Crime Category'(28 categorical values) instead of 'Category Type'(903 categorical values) attribute
  - Further reduction of 'NIBRS Crime category' to consist 8 categorical values in new attribute 'Category' 
- Usage of 'Division'(13 categorical values ) instead of 'Zip Code' (122 categorical values) 
  - Cleaning the 'Division' attribute - bringing values to consistent format, thus reducing to 8 categorical values 

```{r dallas_crime_type}
category_bins = tribble(
  ~Sub,~Category,~CatNum,
  "BRIBERY","ALL OTHER OFFENSES",1,
  "HUMAN TRAFFICKING","ALL OTHER OFFENSES",1,
  "PORNOGRAPHY/ OBSCENE MATERIAL","ALL OTHER OFFENSES",1,
  "FAMILY OFFENSES, NONVIOLENT","ALL OTHER OFFENSES",1,
  "DRUG/ NARCOTIC VIOLATIONS","ALL OTHER OFFENSES",1,
  "ARSON","DESTRUCTION/ DAMAGE/ VANDALISM OF PROPERTY",2,
  "DESTRUCTION/ DAMAGE/ VANDALISM OF PROPERTY","DESTRUCTION/ DAMAGE/ VANDALISM OF PROPERTY",2,
  "TRAFFIC VIOLATION - NON HAZARDOUS","TRAFFIC VIOLATION",3,
  "DRIVING UNDER THE INFLUENCE","TRAFFIC VIOLATION",3,
  "TRAFFIC VIOLATION - HAZARDOUS","TRAFFIC VIOLATION",3,
  "ROBBERY","BURGLARY/ BREAKING & ENTERING",4,
  "MOTOR VEHICLE THEFT","LARCENY/ THEFT OFFENSES",5,
  "KIDNAPPING/ ABDUCTION","ASSAULT OFFENSES",6,
  "ANIMAL OFFENSES","ASSAULT OFFENSES",6,
  "HOMICIDE OFFENSES","ASSAULT OFFENSES",6,
  "WEAPON LAW VIOLATIONS","ASSAULT OFFENSES",6,
  "KIDNAPPING/ ABDUCTION","ASSAULT OFFENSES",6,
  "HOMICIDE OFFENSES","ASSAULT OFFENSES",6,
  "EMBEZZELMENT","FRAUD OFFENSES",7,
  "COUNTERFEITING / FORGERY","FRAUD OFFENSES",7,
  "DRUNKENNESS","DRUNKENNESS/TRESPASSING/NUISANCE",8,
  "DISORDERLY CONDUCT","DRUNKENNESS/TRESPASSING/NUISANCE",8,
  "LIQUOR LAW VIOLATIONS","DRUNKENNESS/TRESPASSING/NUISANCE",8,
  "TRESPASS OF REAL PROPERTY","DRUNKENNESS/TRESPASSING/NUISANCE",8
  )

dallas_crime_type<-dallas_incidents%>%
  inner_join(category_bins, by = c("NIBRS Crime Category" = "Sub"))%>%
  select(`Division`,`week of the day`,`time slot of occurence`,`Category`,`NIBRS Crime Category`,`rounded time`)%>%
  filter( !is.na(`Division`) & !is.na(`week of the day`) & !is.na(`time slot of occurence`) & !is.na(`Category`) & !is.na(`NIBRS Crime Category`) & !is.na(`rounded time`))%>%
  mutate(`Category`=factor(Category),`Division`=factor(`Division`),`week of the day`=factor(`week of the day`),`time slot of occurence`=factor(`time slot of occurence`),`NIBRS Crime Category`=factor(`NIBRS Crime Category`),`rounded time`=factor(`rounded time`))
```
### 4.2.2 Following chunk performs evaluation of variable importance using chi-square test
*Null hypothesis : There is no association between 2 variables*

*Following combinations of attributes were considered for the evaluation*

*Following interpretations can be drawn from the tests*
```{r feature selection (classification)}

#Following code does not include `NIBRS Crime Category` as it had lower significance than `Category`
tbl_dallas_zrwt<-dallas_crime_type%>%
  categorize(`Category`,`Division`,`week of the day`,`time slot of occurence`)

if(chisq.test(table(tbl_dallas_zrwt),simulate.p.value = TRUE)[[3]]<0.05){
    print("p-value is significant  - Null Hypothesis rejected")
  }else{
    print("Null hypothesis sustained - no significant association observed")
  }
```
# 5. Model Training
- Both classification and regression models are trained using the explanatory variables that had highest importance(from our inferential statistics tools) in predicting the future outcome
- Divide the data into training(75%) and testing(25%)
- Parameters auto-tune length set to 10
- Cross validation of chunk size 10 to reduce overfitting

## 5.1 Regression Model
- Using the explanatory variables `week of the day`, `rounded time` and `division` for predicting the `crime frequency`
- generating dummy variables of the dataframe 
- Using the log transformation for the response variable `crime frequency` for normalization
- Using linear regression model and gradient boosting algorithms.
- preprocess the target attribute to scale and center
- Using RMSE metrics for cross validation evaluation

*Following chunk performs the task*
```{r regression training}
dmy <- dummyVars(freq  ~., data = dallas_crime_rate,fullRank = T)
reg_train_transformed <- data.frame(predict(dmy, newdata = dallas_crime_rate))
reg_train_transformed$`freq`<-(dallas_crime_rate$freq)
reg_intrain <- createDataPartition(y = (dallas_crime_rate$freq), p= 0.75, list = FALSE)
reg_training <- reg_train_transformed[reg_intrain,]
reg_testing <- reg_train_transformed[-reg_intrain,]
set.seed(100)

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,verboseIter = FALSE)

  lm_reg_model <- train(`freq` ~., data = reg_training, method="lm", metric="RMSE",
                        preProcess=c("BoxCox"), tuneLength = 10,
                      trControl=trctrl)
 
  gbm_reg_model <- train(`freq` ~., data = reg_training, method="gbm", metric="RMSE",
                        preProcess=c("BoxCox"), tuneLength = 10,
                      trControl=trctrl)
 
 
  save(lm_reg_model, file = "lm_regression.rda")
  save(gbm_reg_model, file = "gbm_regression.rda")

```
## 5.2 Classification Model
- Using the explanatory varibales `week of the day`,`division` and `time slot of occurence` for predicting `Category` (crime type)
- generating dummy variables of the dataframe
- Using the algorithms SVM,Random Forest and Naive Bayes.
- preprocess the target attribute to scale and center

```{r classification training}

dmy <- dummyVars(Category  ~., data = dallas_crime_type,fullRank = T)
cls_train_transformed <- data.frame(predict(dmy, newdata = dallas_crime_type))

cls_train_transformed$`Category`<-dallas_crime_type$Category


cls_intrain <- createDataPartition(y = dallas_crime_type$`Category`, p= 0.75, list = FALSE)
cls_training <- cls_train_transformed[cls_intrain,]
cls_testing <- cls_train_transformed[-cls_intrain,]

trctrl <- trainControl(method = "repeatedcv",number = 10, repeats = 3,verboseIter = FALSE)
 set.seed(111)
   svm_Linear_cls_model <- train(`Category` ~., data = cls_training, method = "svmLinear",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)
   random_Forest_cls_model<-train(`Category` ~., data = cls_training, method = "rf",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)
   naive_bayes_cls_model<-train(`Category` ~., data = cls_training, method = "nb",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)

 save(svm_Linear_cls_model, file = "svm_classification.rda")
 save(random_Forest_cls_model, file = "rf_classification.rda")
 save(naive_bayes_cls_model, file = "nb_classification.rda")

```

# 6 Model Prediction and Evaluation

## 6.1 Regression Model 
- Evaluation using `Area under the curve`
```{r regression evaluation}
load("lm_regression.rda")
load("gbm_regression.rda")
lm_test_pred <- predict(lm_reg_model, newdata = reg_testing)
gbm_test_pred <- predict(gbm_reg_model, newdata = reg_testing)
print("Linear Regression Model Performance :")

plot(as_data_frame(lm_test_pred)$value,as_data_frame(reg_testing$freq)$value,
      xlab="predicted",ylab="actual",main="Linear Regression Performance")
 abline(a=0,b=1)

 plot(as_data_frame(gbm_test_pred)$value,as_data_frame(reg_testing$freq)$value,
      xlab="predicted",ylab="actual",main="Gradient Boosting Performance")
 abline(a=0,b=1)

summary(lm_reg_model)
print("Gradient Boosting Model Performance :")
summary(gbm_reg_model)
```

## 6.2 Classification Model
- Evaluation using `Confusion Matrix`

```{r classification evaluation}
load("svm_classification.rda")
load("rf_classification.rda")
load("nb_classification.rda")
test_pred_svm <- predict(svm_Linear_cls_model, newdata = cls_testing)
test_pred_rf <- predict(random_Forest_cls_model, newdata = cls_testing)
test_pred_nb <- predict(naive_bayes_cls_model, newdata = cls_testing)
print("SVM Model Performance :")
confusionMatrix(test_pred_svm, factor(cls_testing$`Category`))
print("Random Forest Model Performance :")
confusionMatrix(test_pred_rf, factor(cls_testing$`Category`))
print("Naive Bayes Performance :")
confusionMatrix(test_pred_nb, factor(cls_testing$`Category`))
```

# 7 Interpretations and Scope of Future Improvement

## 7.1 Interpretations
- Regression Model Evaluation Score : RMSE : Standard Error : Around 17
- Classification Accuracy : 100%(SVM), 99.98% (RF), 68%(Naive Bayes)

## 7.2 Scope for Future Improvement
- Predicted values in regression fit well with the actual values as per the plotted graphs of actual vs predicted.
- Accuracy is high for SVM,RF - High overfitting possibile (or over-simplified model), Accuracy is moderate for Naive Bayes method
- Better feature engineering and complex selection of explanatory attributes must be addressed
