---
title: "An Approach to Predictive Policing with Dallas City by Team RAAS"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE,message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Load Required packages
```{r libraries,message=FALSE, warning=FALSE}
library(tibble)
library(dplyr)
library(magrittr)
library(readr)
library(zipcode)
library(lubridate)
library(stringr)
library(ggplot2)
library(forcats)
library(plotly)
library(scales)
library(MESS)
library(caret)
data("zipcode")
```

# 1. Data Reading
*Objective : Read CSV from data source*
- Following chunk reads the source csv and loads only required attributes into a dataframe object for the use
*Following chunk performs Data Reading*
```{r Reading, echo=TRUE,message=FALSE, warning=FALSE}
#Uncomment below import line only when running the script for first time, to avoid multiple time download of 400+Mb sized dataset
dallas<-read_csv('https://www.dropbox.com/s/7ldxwrsyd10zx95/Police_Incidents.csv?dl=1')
dallas%<>%select(`Service Number ID`,`Type  Location`,`Division`,`Sector`,`Council District`,`Call Received Date Time`,`Victim Gender`,`Victim Age at Offense`,`Offense Status`,`NIBRS Crime Category`,`Zip Code`,`Hate Crime Description`)
#as_tibble(dallas)
#summary(dallas)
```

# 2. Data Pre-processing
*Objective : Generate dataframes dallas_incidents,dallas_crime_type and dallas_crime_rate. Dataframe dallas_indcidents must be suitable for Exploratory data analysis.*
- Filter the required attributes and ignore the non-NA values
- Transforms the attribute 'call received date time' string to R datetime object and sort them in ascending order  
- Compute a new attribute 'week of the day'(name of the weekday, incident occured viz Mon,Tue and so on), 'rounded time'(Hours being rounded off to closest value and only hour value is extracted from the rounded date) and week number from 'call recieved date time'
- Transform values of 'rounded time' to four ordinal values and compute 'time slot of occurence' attribute.
- Clean the dataset to include data only from the city "Dallas"
- To remove short head and to keep dataset symmetric, filter rows corresponding to value from "12/31/2016 23:59:59" to "01/06/2019 00:00:00" (This date range consists of equal number of Mon,Tues,Wed etc of 105 counts)
- Unselect the attributes that are not further required.
*Following chunk performs Transformation/Cleaning*
```{r Transformation/Cleaning,message=FALSE, warning=FALSE}
time_slot_vec=seq(0,24,6)
labels_vec=c("0-6","7-12","13-18","19-23")
age_breaks <- c(seq(17, 97, by = 20),Inf)


age_labels <- c(paste(seq(17, 96, by = 20), seq(0 + 37 - 1, 97 - 1, by = 20),
                sep = "-"), paste(96, "+", sep = "")) 

dallas$`Zip Code`=clean.zipcodes(dallas$`Zip Code`)

#Dataframe dallas_incidents suitable for visualizing data
dallas_incidents<-dallas%>%
  +   filter(!is.na(`Offense Status`) & !is.na(`Division`) & !is.na(`Call Received Date Time`) & !is.na(`Zip Code`) & !is.na(`NIBRS Crime Category`) & !is.na(`Type  Location`) & !is.na(Sector) & !is.na(`Council District`) & !is.na(`Victim Age at Offense`)  & !is.na(`Hate Crime Description`))%>%
  inner_join(zipcode, by = c("Zip Code" = "zip"))%>%
  filter(`city`=="Dallas")%>%
  mutate(`Division`=str_to_upper(str_replace(`Division`," ","")))%>%
  mutate(`Call Received Date Time`= as_datetime(mdy_hms(`Call Received Date Time`)))%>%
  filter(`Call Received Date Time`>as_datetime(mdy_hms("12/31/2016 23:59:59")) &  `Call Received Date Time`<as_datetime(mdy_hms("01/06/2019 00:00:00")))%>%
  mutate(`week of the day`=lubridate::wday(`Call Received Date Time`,label = TRUE, abbr = FALSE),`week number of the day`=lubridate::wday(`Call Received Date Time`),`rounded time`=hour(round_date(`Call Received Date Time`,"hour")))%>%
  mutate(`time slot of occurence`=cut(`rounded time`,breaks = time_slot_vec,labels = labels_vec,include.lowest = TRUE))%>%
  arrange(`Call Received Date Time`)%>%
  select(-`city`,-`state`,-`latitude`,-`longitude`)

```
# 3. Exploratory Data Analysis
*Objective : To evaluate the pattern/trend in the dataset that could 1. Answer some basic questions 2. Help in selecting attributes for predictive analysis*

## 3.1 What crimes are frequent?

### Following can be interpreted from the graph
- Larcency/Theft offences are the highest frequent in occurence, followed by Assault offences and Property related crimes.
- Numerous crimes are very negligible in occurence. Crimes such as Human trafficking, bribery, drunkeness among some others are very rare in appearance.
- Some categories such as 'Miscellenaous' and 'Other crimes' are ambigous. However, they have a decent frequency of occurence.

```{r ggplot_frq_crime, echo=FALSE,message=FALSE, warning=FALSE}
ggplot_frq_crime<-dallas_incidents%>%
  ggplot(aes(fct_infreq(`NIBRS Crime Category`),fill=`NIBRS Crime Category`))+geom_bar(position = "stack") +  labs(title="Crime Categories Frequency", subtitle="count for every kind of crime that occured", y="Frequency", x="Crime") + coord_flip() + theme(legend.position="none")

ggplotly(ggplot_frq_crime)
```

## 3.2 How victim gender and the time of crime are related and volume of crime for each time slot.

### Following can be interpreted from the graph
- Interesting observation is Male are more prone to be victim during late night (00:00 to 06:00). 
- Females victims are higher during the afternoon slot (13:00 to 18:00)

Please note : above observations could also be misleading as the relative population size of the city is not being considered.
```{r dallas_gender_and_timeslot, echo=FALSE,message=FALSE, warning=FALSE}
dallas_gender_and_timeslot<-dallas_incidents%>%
filter( (`Victim Gender`=="Male" | `Victim Gender`=="Female"))%>%
  group_by(`Victim Gender`,`time slot of occurence`)%>%
  summarise (`number of crimes` = n()) %>%
  mutate(percentage = sprintf("%.1f%%",(`number of crimes` / sum(`number of crimes`))*100))

ggplot_dgt<-ggplot(dallas_gender_and_timeslot,aes(x=`Victim Gender`,y=`number of crimes`,label=percentage, fill = `time slot of occurence`))  +
  geom_bar(position = "stack",stat = "identity")+geom_text( size = 3, position = position_stack(vjust = 0.5))+labs(x = "Victim Gender",y="Number of Crimes",title="Victim Gender and corresponding Time Slot of Crime Occurence")+guides(fill=guide_legend(title = "Time Slot"))
ggplotly(ggplot_dgt)
```

## 3.3 How crimes relate to the time of day

### Following can be interpreted from the graph
- The top 3 crimes mentioned earlier i.e, Larcency/Theft offences , Assault offences and Property related crimes seems to have equal number of occurences during late night slight (00:00 to 6:00). This means lesser possibilities of occurence of Larcency/Theft offences during this time slot in comparison to Assault offences and Property related crimes.
- Another interesting observation is - Burglary /Breaking and entering is relatively very low during evening times (19:00 to 6:00) in comparison to day time (7:00 to 18:00) - This observation also related directly to the above observation 

```{r dallas_crime_and_timeslot, echo=FALSE,message=FALSE, warning=FALSE}
dallas_crime_and_timeslot<-dallas_incidents%>%
  group_by(`NIBRS Crime Category`,`time slot of occurence`)%>%
  summarise(`number of crimes` = n())%>%
  arrange(`number of crimes`,.by_group = TRUE)

ggplot_dct=ggplot(dallas_crime_and_timeslot,aes(x=reorder(`NIBRS Crime Category`,-`number of crimes`),y=`number of crimes`, fill = `time slot of occurence`)) +geom_bar(position = "stack",stat = "identity")+coord_flip()+labs(x="NIBRS Crime Category",y="Number of Crimes",title = "NBIRS Crime category and corresponding Time Slot of Occurence")+guides(fill=guide_legend(title = "Time Slot"))
ggplotly(ggplot_dct)
```

## 3.4 How crimes are related to days of the week and time slot of occurence

### Following can be interpreted from the graph
- Late night (00:00 to 6:00) on weekends has higher occurence of crime in comparison to that of weekdays - possible reason could be higher number of people staying outdoors on weekends leading to higher chances of crimes.
- Monday and Friday seems to have highest number of crimes in the week.
- Day time (7:00 to 18:00) on weekends seems to have lesser frequency of crimes in comparison to that of weekdays - possible reason could be fewer number of people being outdoors leading to lesser chances of crimes.

```{r dallas_crime_rate_per_week_and_timeslot, echo=FALSE,message=FALSE, warning=FALSE}
dallas_crime_rate_per_week_and_timeslot<-dallas_incidents%>%
  group_by(`time slot of occurence`,`week of the day`)%>%
  summarize(`number of crimes` = n())%>%
  mutate(percentage = sprintf("%.1f%%",(`number of crimes` / sum(`number of crimes`))*100))

ggplot_dcrwt=dallas_crime_rate_per_week_and_timeslot%>%
  ggplot(aes(x=`week of the day`,y=`number of crimes`, fill = `time slot of occurence` , label=percentage)) +geom_bar(position = "stack",stat = "identity")+geom_text( size = 3, position = position_stack(vjust = 0.5))+coord_flip()+labs(x="Day in the Week",y="Number of Crimes",title = "Days of Week and Corresponding observed Crimes per Time Slot")+guides(fill=guide_legend(title = "Time Slot"))

ggplotly(ggplot_dcrwt)
```
## 3.5  What percentage of crimes are "Hate crimes"? 
###Not feasible 
- Since 99% of instance values are `none and unknown´ , there is not enough evidence to suppport the conclusion that maximum hate  crimes are against Anti Homosexual and Anti black communities, which can  be interpreted  from the instance values.
```{r Hate Crime Analysis, echo=FALSE}

ggplot_hc <-dallas_incidents%>%
select(`Hate Crime Description`)%>%
group_by(`Hate Crime Description`)%>%
summarize( `number of crimes` = n())
ggplot_hc

```
##3.6 What age group in adults (over 18) is highly prone to be a victim? changed to What age group in adults (over 16) is highly prone to be a victim?
###Following can be interpreted from the graphs
- Minimum age = 17 and Maximum age = 118.
- Density plot depicts the spread of the age group variable, showing that maximum instances arein 17-36 age group.
- The bar graph depicts that the maximum percentage of crime victims belong to 17-36 age group, followed by 37-56 age group and minimum in the 96+ age group.

```{r age group ,echo=FALSE}
range(dallas_incidents$`Victim Age at Offense`)

dallas_incidents%>%
group_by(`age group`)%>%
summarize( 
          `number of crimes` = n())

ggplot_ag<-ggplot(data = dallas_incidents, aes(x = `age group`)) + geom_density( alpha = .5, fill = "blue")
ggplot_ag

ggplot_age<-dallas_incidents%>%
group_by(`age group`)%>%
summarize( `number of crimes` = n())%>%
mutate(percentage = sprintf("%.1f%%",(`number of crimes` / sum(`number of crimes`))*100))

ggplot(data = ggplot_age, mapping = aes(x=`age group`,y=`number of crimes`,label=percentage, fill = `age group`))  +
  geom_bar(position = "stack",stat = "identity")+geom_text( size = 3, position = position_stack(vjust = 0.5))+labs(x = "Age group",y="Number of Crimes",title="Age group suffering the wrath of Crimes ")
ggplotly()
```

# 4. Feature Selection for Predictive Analysis
- Two types of problems were designed for the given dataset : 1. Regression, 2. Classification

- Objectives : 
 - 1. Evaluate attributes and their correlation
 - 2. Generate datasets dallas_crime_rate(regression) and dallas_crime_type(classification) suitable to solve the designed problems

## 4.1 Feature Selection for Regression problem

### 4.1.1 Following chunk performs the generation of dataframe dallas_crime_rate

#### 4.1.1.1 Following steps taken to generate dallas_crime_rate dataframe
- All steps to generate dallas_incidents dataframe
- group by 'Division', 'rounded time' and 'week number of the day' and summarize the frequency of records to new attribute 'freq'

#### 4.1.1.2 Following steps were completed done during preliminary features selection phase :
- Reduction of Location Type attribute to 4 categorical values from 73
```{r dallas_crime_rate,message=FALSE, warning=FALSE}

type_location_bins<-tribble(
  ~Sub,~LocationType,~LocNum,
  "Highway, Street, Alley ETC","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Airport - Love Field","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Medical Facility","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Financial Institution","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Bank/Savings And Loan","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Construction Site","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Religious Institution","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Government Facility","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Church/Synagogue/Temple/Mosque","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Shopping Mall","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Parking Lot (Park)","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Airport - All Others","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Jail/Prison/Penitentiary/Corrections Fac","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School - Elementary/Secondary","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "ATM Separate from Bank","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Daycare Facility","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Military Installation","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Outdoor Area Public/Private","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Amusement Park","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "PHARM","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Park","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Arena/Stadium/Fairgrounds/Coliseum","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School/Daycare","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "City Park/Rec/Tennis/Golf/Trail","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School - College/University","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Government/Public Building","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Community/ Recreation Center","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Dock/Wharf/Freight/Modal Terminal","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Shelter - Mission/Homeless","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "School/College","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Camp/Campground","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Lake/Waterway/Beach","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Apartment Complex/Building","Private/Individual Locations (Residences and others)",4,
  "Convenience Store","Commercial Establishments (Restaurants/Stores)",2,
  "Gas or Service Station","Commercial Establishments (Restaurants/Stores)",2,
  "Bar/NightClub/DanceHall ETC.","Commercial Establishments (Restaurants/Stores)",2,
  "Parking Lot (Apartment)","Private/Individual Locations (Residences and others)",4,
  "Entertainment/Sports Venue","Commercial Establishments (Restaurants/Stores)",2,
  "Parking (Business)","Commercial Establishments (Restaurants/Stores)",2,
  "Storage Facility","Commercial Establishments (Restaurants/Stores)",2,
  "Single Family Residence - Vacant","Private/Individual Locations (Residences and others)",4,
  "Department/Discount Store","Public Locations (Hospitals/Parks/ATMs/Streets/Schools)",1,
  "Condominium/Townhome Residence","Private/Individual Locations (Residences and others)",4,
  "Shopping Mall","Commercial Establishments (Restaurants/Stores)",2,
  "Grocery/Supermarket","Commercial Establishments (Restaurants/Stores)",2,
  "Specialty Store (In a Specific Item)","Commercial Establishments (Restaurants/Stores)",2,
  "Personal Services","Private/Individual Locations (Residences and others)",4,
  "Tribal Lands","Private/Individual Locations (Residences and others)",4,
  "Restaurant/Food Service/TABC Location","Commercial Establishments (Restaurants/Stores)",2,
  "Apartment Residence","Private/Individual Locations (Residences and others)",4,
  "Single Family Residence - Occupied","Private/Individual Locations (Residences and others)",4,
  "Retail Store","Commercial Establishments (Restaurants/Stores)",2,
  "Business Office","Commercial Establishments (Restaurants/Stores)",2,
  "Motor Vehicle","Private/Individual Locations (Residences and others)",4,
  "Commercial Property Occupied/Vacant","Commercial Establishments (Restaurants/Stores)",2,
  "Industrial/Manufacturing","Commercial Establishments (Restaurants/Stores)",2,
  "Hotel/Motel/ETC","Commercial Establishments (Restaurants/Stores)",2,
  "Auto Dealership New/Used","Commercial Establishments (Restaurants/Stores)",2,
  "Liquor Store","Commercial Establishments (Restaurants/Stores)",2,
  "Rental Storage Facility","Commercial Establishments (Restaurants/Stores)",2,
  "Other","Others",3,
  "Cyberspace","Others",3
)

dallas_crime_rate<-dallas_incidents%>%
  select(`rounded time`,`week number of the day`,`Division`,`Type  Location`)%>%
  inner_join(type_location_bins, by = c("Type  Location" = "Sub"))%>%
  mutate(`rounded time`=factor(`rounded time`),`week number of the day`=factor(`week number of the day`),`Division`=factor(`Division`),LocationType = factor(LocationType))%>%
  group_by(`Division`,`rounded time`,`week number of the day`)%>%
  summarise(freq=n())

```
### 4.1.2 Following chunk performs evaluation of variable importance using boxplot visualizations and anova method

#### 4.1.2.1 Following  attributes were considered(in various combinations) for the evaluation
- frequency ~ (ZipCode, LocationType, rounded time, NBIRS Category, time slot of occurence, week number of day and Division )

#### 4.1.2.2 Following interpretations can be drawn from the tests
- There were too many outliers for ZipCode and NBIRS Category in boxplot - hence can be rejected
- Another reason for ignoring NBIRS category completely is - it is not a meaningful variable in describing the response variable
- There were not too many differences in mean level of 'time slot of occurence' in comparison to that of 'rounded time' from boxplot - hence time slot of occurence can be rejected 
- Anova method shows combinations of 'Division', 'rounded time' and 'week number of the day' gave much favourable p-value (less than 0.05) than that of 'LocationType', 'rounded time' and 'week number of day'. Thus we select the combination that has relatively lower p-value.

Please note : following chunk consists only those variables that were finally selected. 
```{r feature selection (regression),message=FALSE, warning=FALSE}
d_mod=lm(dallas_crime_rate$`freq` ~ dallas_crime_rate$`Division`+dallas_crime_rate$`week number of the day`+dallas_crime_rate$`rounded time`, data = dallas_crime_rate) 
summary(d_mod)
anova(d_mod)
#confint(d_mod)
print(as_tibble(dallas_crime_rate))
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`rounded time`, y=dallas_crime_rate$`freq`)) + geom_boxplot()
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`Division`, y=dallas_crime_rate$`freq`)) + geom_boxplot()
ggplot(dallas_crime_rate, aes(x=dallas_crime_rate$`week number of the day`, y=dallas_crime_rate$`freq`)) + geom_boxplot()

```
## 4.2 Feature Selection for Classification problem 

### 4.2.1 Following chunk performs the generation of dataframe dallas_crime_type

#### 4.2.1.1 Following steps taken to generate dallas_crime_type dataframe
- All steps to generate dallas_incidents dataframe
- group by 'Division', 'rounded time' and 'week number of the day' and summarize the frequency of records to new attribute 'freq'

#### 4.2.1.2 Following steps were completed done during preliminary features selection phase :
- Reduction of Location Type attribute to 4 categorical values from 73
- Usage of 'NIBRS Crime Category'(28 categorical values) instead of 'Category Type'(903 categorical values) attribute
  - Further reduction of 'NIBRS Crime category' to consist 8 categorical values in new attribute 'Category' 
- Usage of 'Division'(13 categorical values ) instead of 'Zip Code' (122 categorical values) 
  - Cleaning the 'Division' attribute - bringing values to consistent format, thus reducing to 8 categorical values 

```{r dallas_crime_type,message=FALSE, warning=FALSE}
category_bins = tribble(
  ~Sub,~Category,~CatNum,
  "BRIBERY","ALL OTHER OFFENSES",1,
  "HUMAN TRAFFICKING","ALL OTHER OFFENSES",1,
  "PORNOGRAPHY/ OBSCENE MATERIAL","ALL OTHER OFFENSES",1,
  "FAMILY OFFENSES, NONVIOLENT","ALL OTHER OFFENSES",1,
  "DRUG/ NARCOTIC VIOLATIONS","ALL OTHER OFFENSES",1,
  "ARSON","DESTRUCTION/ DAMAGE/ VANDALISM OF PROPERTY",2,
  "DESTRUCTION/ DAMAGE/ VANDALISM OF PROPERTY","DESTRUCTION/ DAMAGE/ VANDALISM OF PROPERTY",2,
  "TRAFFIC VIOLATION - NON HAZARDOUS","TRAFFIC VIOLATION",3,
  "DRIVING UNDER THE INFLUENCE","TRAFFIC VIOLATION",3,
  "TRAFFIC VIOLATION - HAZARDOUS","TRAFFIC VIOLATION",3,
  "ROBBERY","BURGLARY/ BREAKING & ENTERING",4,
  "MOTOR VEHICLE THEFT","LARCENY/ THEFT OFFENSES",5,
  "KIDNAPPING/ ABDUCTION","ASSAULT OFFENSES",6,
  "ANIMAL OFFENSES","ASSAULT OFFENSES",6,
  "HOMICIDE OFFENSES","ASSAULT OFFENSES",6,
  "WEAPON LAW VIOLATIONS","ASSAULT OFFENSES",6,
  "KIDNAPPING/ ABDUCTION","ASSAULT OFFENSES",6,
  "HOMICIDE OFFENSES","ASSAULT OFFENSES",6,
  "EMBEZZELMENT","FRAUD OFFENSES",7,
  "COUNTERFEITING / FORGERY","FRAUD OFFENSES",7,
  "DRUNKENNESS","DRUNKENNESS/TRESPASSING/NUISANCE",8,
  "DISORDERLY CONDUCT","DRUNKENNESS/TRESPASSING/NUISANCE",8,
  "LIQUOR LAW VIOLATIONS","DRUNKENNESS/TRESPASSING/NUISANCE",8,
  "TRESPASS OF REAL PROPERTY","DRUNKENNESS/TRESPASSING/NUISANCE",8
  )

dallas_crime_type<-dallas_incidents%>%
  inner_join(category_bins, by = c("NIBRS Crime Category" = "Sub"))%>%
  select(`Division`,`week of the day`,`time slot of occurence`,`Category`,`NIBRS Crime Category`,`rounded time`)%>%
  filter( !is.na(`Division`) & !is.na(`week of the day`) & !is.na(`time slot of occurence`) & !is.na(`Category`) & !is.na(`NIBRS Crime Category`) & !is.na(`rounded time`))%>%
  mutate(`Category`=factor(Category),`Division`=factor(`Division`),`week of the day`=factor(`week of the day`),`time slot of occurence`=factor(`time slot of occurence`),`NIBRS Crime Category`=factor(`NIBRS Crime Category`),`rounded time`=factor(`rounded time`))
```
### 4.2.2 Following chunk performs evaluation of variable importance using chi-square test
- Null hypothesis : There is no association between 2 variables

#### 4.2.2.1 Following  attributes were considered(in various combinations) for the evaluation
- Crime Category ~ (rounded time, time slot of occurence, week of the day and Division)
#### 4.2.2.2 Following interpretations can be drawn from the tests
- both combinations of (rounded time, week of the day and Division) and (time slot of occurence, week of the day and Division) passes chi-square test. However, we pick the combination that contains time slot of occurence as it has only factor levels in comparison to that of 24 in rounded time for building model with better accuracy.
- Another reason to reject rounded time is the duration of traning the model is higher.
```{r feature selection (classification),message=FALSE, warning=FALSE}

#Following code does not include `NIBRS Crime Category` as it had lower significance than `Category`
tbl_dallas_zrwt<-dallas_crime_type%>%
  categorize(`Category`,`Division`,`week of the day`,`time slot of occurence`)

if(chisq.test(table(tbl_dallas_zrwt),simulate.p.value = TRUE)[[3]]<0.05){
    print("p-value is significant  - Null Hypothesis rejected")
  }else{
    print("Null hypothesis sustained - no significant association observed")
  }
```
# 5. Model Training
- Both classification and regression models are trained using the explanatory variables that had highest importance(from our inferential statistics tools) in predicting the future outcome
- Divide the data into training(75%) and testing(25%)
- Parameters auto-tune length set to 10
- Resampling method chosen : Cross validation of chunk size 10 

## 5.1 Regression Model
- Using the explanatory variables `week of the day`, `rounded time` and `division` for predicting the `crime frequency`
- generating dummy variables of the dataframe 
- Using the log transformation for the response variable `crime frequency` for normalization
- Using linear regression model and gradient boosting algorithms.
- preprocess the target attribute to scale and center
- Using RMSE metrics for cross validation evaluation

```{r regression training,message=FALSE, warning=FALSE,results = 'hide'}
dmy <- dummyVars(freq  ~., data = dallas_crime_rate,fullRank = T)
reg_train_transformed <- data.frame(predict(dmy, newdata = dallas_crime_rate))
reg_train_transformed$`freq`<-(dallas_crime_rate$freq)
reg_intrain <- createDataPartition(y = (dallas_crime_rate$freq), p= 0.75, list = FALSE)
reg_training <- reg_train_transformed[reg_intrain,]
reg_testing <- reg_train_transformed[-reg_intrain,]
set.seed(100)

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,verboseIter = FALSE)

  lm_reg_model <- train(`freq` ~., data = reg_training, method="lm", metric="RMSE",
                        preProcess=c("BoxCox"), tuneLength = 10,
                      trControl=trctrl)
 
  gbm_reg_model <- train(`freq` ~., data = reg_training, method="gbm", metric="RMSE",
                        preProcess=c("BoxCox"), tuneLength = 10,
                      trControl=trctrl)
 
 
  save(lm_reg_model, file = "lm_regression.rda")
  save(gbm_reg_model, file = "gbm_regression.rda")

```
## 5.2 Classification Model
- Using the explanatory varibales `week of the day`,`division` and `time slot of occurence` for predicting `Category` (crime type)
- generating dummy variables of the dataframe
- Using the algorithms SVM,Random Forest and Naive Bayes.
- preprocess the target attribute to scale and center

```{r classification training,message=FALSE, warning=FALSE,results = 'hide'}

dmy <- dummyVars(Category  ~., data = dallas_crime_type,fullRank = T)
cls_train_transformed <- data.frame(predict(dmy, newdata = dallas_crime_type))

cls_train_transformed$`Category`<-dallas_crime_type$Category


cls_intrain <- createDataPartition(y = dallas_crime_type$`Category`, p= 0.75, list = FALSE)
cls_training <- cls_train_transformed[cls_intrain,]
cls_testing <- cls_train_transformed[-cls_intrain,]

trctrl <- trainControl(method = "repeatedcv",number = 10, repeats = 3,verboseIter = FALSE)
 set.seed(111)
   svm_Linear_cls_model <- train(`Category` ~., data = cls_training, method = "svmLinear",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)
   random_Forest_cls_model<-train(`Category` ~., data = cls_training, method = "rf",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)
   naive_bayes_cls_model<-train(`Category` ~., data = cls_training, method = "nb",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)

 save(svm_Linear_cls_model, file = "svm_classification.rda")
 save(random_Forest_cls_model, file = "rf_classification.rda")
 save(naive_bayes_cls_model, file = "nb_classification.rda")

```

# 6 Model Prediction and Evaluation

## 6.1 Regression Model 
- Evaluation using `Predicted v/s Actual Dataset Plot` and `RMSE Mean`
```{r regression evaluation,message=FALSE, warning=FALSE}
load("lm_regression.rda")
load("gbm_regression.rda")
lm_test_pred <- predict(lm_reg_model, newdata = reg_testing)
gbm_test_pred <- predict(gbm_reg_model, newdata = reg_testing)
print("Linear Regression Model Performance :")

plot(as_data_frame(lm_test_pred)$value,as_data_frame(reg_testing$freq)$value,
      xlab="predicted",ylab="actual",main="Linear Regression Performance")
 abline(a=0,b=1)

 plot(as_data_frame(gbm_test_pred)$value,as_data_frame(reg_testing$freq)$value,
      xlab="predicted",ylab="actual",main="Gradient Boosting Performance")
 abline(a=0,b=1)

summary(lm_reg_model)
print("Gradient Boosting Model Performance :")
summary(gbm_reg_model)
print("Comparison on performance : ")
res <- resamples(list(lm = lm_reg_model, gbm = gbm_reg_model))
summary(res)
```

## 6.2 Classification Model
- Evaluation using `Confusion Matrix`

```{r classification evaluation,message=FALSE, warning=FALSE}
load("svm_classification.rda")
load("rf_classification.rda")
load("nb_classification.rda")
test_pred_svm <- predict(svm_Linear_cls_model, newdata = cls_testing)
test_pred_rf <- predict(random_Forest_cls_model, newdata = cls_testing)
test_pred_nb <- predict(naive_bayes_cls_model, newdata = cls_testing)
print("SVM Model Performance :")
confusionMatrix(test_pred_svm, factor(cls_testing$`Category`))
print("Random Forest Model Performance :")
confusionMatrix(test_pred_rf, factor(cls_testing$`Category`))
print("Naive Bayes Performance :")
confusionMatrix(test_pred_nb, factor(cls_testing$`Category`))
```

# 7 Interpretations and Scope for Future Improvement

## 7.1 Interpretations

- Regression Model Evaluation 
-- RMSE Mean : 14(gbm) > 17(lm)
-- Rsquared : 0.85(lm) > 0.82(gbm)

- Classification Model Evaluation 
-- Accuracy : 100%(SVM) > 99.98% (RF) > 68%(Naive Bayes)

## 7.2 Scope for Future Improvement
- Predicted values in regression fit well with the actual values as per the plotted graphs of actual vs predicted.
- Accuracy is high for SVM,RF - High overfitting possibile (or over-simplified model), Accuracy is moderate for Naive Bayes method
- Better feature engineering and complex selection of explanatory attributes must be addressed